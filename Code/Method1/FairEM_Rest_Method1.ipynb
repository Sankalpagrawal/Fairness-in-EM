{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.12"},"colab":{"name":"FairEM_Rest_Method1.ipynb","provenance":[],"collapsed_sections":[]}},"cells":[{"cell_type":"code","metadata":{"id":"3-sIJFZTYLED","colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"ok","timestamp":1621794407448,"user_tz":-330,"elapsed":106102,"user":{"displayName":"Jay Rawal","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gicbrmn_Qxld9lob37iy1Q00RZQJCLx5AygrBt28Q=s64","userId":"02034246470089161035"}},"outputId":"0c01fd83-588d-43ca-f6f4-543ccd84f849"},"source":["!pip install py-entitymatching"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Collecting py-entitymatching\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ab/b1/5cc5896313426495ccf757c228d17550ff32cc37a8a3a6a7aee78532954d/py_entitymatching-0.4.0.tar.gz (2.0MB)\n","\u001b[K     |████████████████████████████████| 2.0MB 2.1MB/s \n","\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from py-entitymatching) (2.23.0)\n","Collecting ipython>=5.6\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/81/d1/8d0ba7589ea4cbf3e80ef8e20616da2cfc3c33187a64b044372aad517512/ipython-7.23.1-py3-none-any.whl (785kB)\n","\u001b[K     |████████████████████████████████| 788kB 31.8MB/s \n","\u001b[?25hRequirement already satisfied: matplotlib>=2.2.4 in /usr/local/lib/python3.7/dist-packages (from py-entitymatching) (3.2.2)\n","Collecting PyPrind\n","  Downloading https://files.pythonhosted.org/packages/ab/b3/1f12ebc5009c65b607509393ad98240728b4401bc3593868fb161fdd3760/PyPrind-2.11.3-py2.py3-none-any.whl\n","Collecting py-stringsimjoin>=0.3.0\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/69/f8/343a7277ce5952a923302bb29ac547a2e3eab45965fdf40a7dd43ed058ef/py_stringsimjoin-0.3.2.tar.gz (1.1MB)\n","\u001b[K     |████████████████████████████████| 1.1MB 25.2MB/s \n","\u001b[?25hRequirement already satisfied: cloudpickle>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from py-entitymatching) (1.3.0)\n","Requirement already satisfied: pyparsing>=2.1.4 in /usr/local/lib/python3.7/dist-packages (from py-entitymatching) (2.4.7)\n","Requirement already satisfied: scikit-learn>=0.22 in /usr/local/lib/python3.7/dist-packages (from py-entitymatching) (0.22.2.post1)\n","Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from py-entitymatching) (1.4.1)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from py-entitymatching) (1.19.5)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->py-entitymatching) (3.0.4)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->py-entitymatching) (2.10)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->py-entitymatching) (1.24.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->py-entitymatching) (2020.12.5)\n","Requirement already satisfied: backcall in /usr/local/lib/python3.7/dist-packages (from ipython>=5.6->py-entitymatching) (0.2.0)\n","Requirement already satisfied: pickleshare in /usr/local/lib/python3.7/dist-packages (from ipython>=5.6->py-entitymatching) (0.7.5)\n","Requirement already satisfied: matplotlib-inline in /usr/local/lib/python3.7/dist-packages (from ipython>=5.6->py-entitymatching) (0.1.2)\n","Requirement already satisfied: pexpect>4.3; sys_platform != \"win32\" in /usr/local/lib/python3.7/dist-packages (from ipython>=5.6->py-entitymatching) (4.8.0)\n","Requirement already satisfied: decorator in /usr/local/lib/python3.7/dist-packages (from ipython>=5.6->py-entitymatching) (4.4.2)\n","Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.7/dist-packages (from ipython>=5.6->py-entitymatching) (56.1.0)\n","Requirement already satisfied: jedi>=0.16 in /usr/local/lib/python3.7/dist-packages (from ipython>=5.6->py-entitymatching) (0.18.0)\n","Requirement already satisfied: pygments in /usr/local/lib/python3.7/dist-packages (from ipython>=5.6->py-entitymatching) (2.6.1)\n","Collecting prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/eb/e6/4b4ca4fa94462d4560ba2f4e62e62108ab07be2e16a92e594e43b12d3300/prompt_toolkit-3.0.18-py3-none-any.whl (367kB)\n","\u001b[K     |████████████████████████████████| 368kB 29.7MB/s \n","\u001b[?25hRequirement already satisfied: traitlets>=4.2 in /usr/local/lib/python3.7/dist-packages (from ipython>=5.6->py-entitymatching) (5.0.5)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=2.2.4->py-entitymatching) (0.10.0)\n","Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=2.2.4->py-entitymatching) (2.8.1)\n","Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=2.2.4->py-entitymatching) (1.3.1)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from py-stringsimjoin>=0.3.0->py-entitymatching) (1.0.1)\n","Requirement already satisfied: pandas>=0.16.0 in /usr/local/lib/python3.7/dist-packages (from py-stringsimjoin>=0.3.0->py-entitymatching) (1.1.5)\n","Collecting py_stringmatching>=0.2.1\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/90/d1/9163e0b0ac3bbb0f727ef8d380985c23066fb98d5005a34483ad76da06b4/py_stringmatching-0.4.2.tar.gz (661kB)\n","\u001b[K     |████████████████████████████████| 665kB 33.6MB/s \n","\u001b[?25hRequirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from py-stringsimjoin>=0.3.0->py-entitymatching) (1.15.0)\n","Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.7/dist-packages (from pexpect>4.3; sys_platform != \"win32\"->ipython>=5.6->py-entitymatching) (0.7.0)\n","Requirement already satisfied: parso<0.9.0,>=0.8.0 in /usr/local/lib/python3.7/dist-packages (from jedi>=0.16->ipython>=5.6->py-entitymatching) (0.8.2)\n","Requirement already satisfied: wcwidth in /usr/local/lib/python3.7/dist-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython>=5.6->py-entitymatching) (0.2.5)\n","Requirement already satisfied: ipython-genutils in /usr/local/lib/python3.7/dist-packages (from traitlets>=4.2->ipython>=5.6->py-entitymatching) (0.2.0)\n","Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.16.0->py-stringsimjoin>=0.3.0->py-entitymatching) (2018.9)\n","Building wheels for collected packages: py-entitymatching, py-stringsimjoin, py-stringmatching\n","  Building wheel for py-entitymatching (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for py-entitymatching: filename=py_entitymatching-0.4.0-cp37-cp37m-linux_x86_64.whl size=2634147 sha256=759951272f6f561fcc67b035816fb4d07a85813d492c09936c92f83e8d1259f2\n","  Stored in directory: /root/.cache/pip/wheels/88/65/50/a8bc0f26e8a82c931658153c4f37cbf5debc22cb0f61dbcd05\n","  Building wheel for py-stringsimjoin (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for py-stringsimjoin: filename=py_stringsimjoin-0.3.2-cp37-cp37m-linux_x86_64.whl size=3723626 sha256=bed002bf720eaa3ad4e7400fdd8458cf3df7e32331d12b402e0e7e3f97c5233b\n","  Stored in directory: /root/.cache/pip/wheels/58/30/8e/6fa463100ff6e8595b131067ec43a118c607f621ac297e7dad\n","  Building wheel for py-stringmatching (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for py-stringmatching: filename=py_stringmatching-0.4.2-cp37-cp37m-linux_x86_64.whl size=2055229 sha256=22b0c98ab9405236146f08bc6ffa07379e36d90f0674657cc429cf3a7132806f\n","  Stored in directory: /root/.cache/pip/wheels/be/8c/5d/bcdaf17d0784738b73e856ebc4061cd3f2509753a83dd71058\n","Successfully built py-entitymatching py-stringsimjoin py-stringmatching\n","\u001b[31mERROR: jupyter-console 5.2.0 has requirement prompt-toolkit<2.0.0,>=1.0.0, but you'll have prompt-toolkit 3.0.18 which is incompatible.\u001b[0m\n","\u001b[31mERROR: google-colab 1.0.0 has requirement ipython~=5.5.0, but you'll have ipython 7.23.1 which is incompatible.\u001b[0m\n","Installing collected packages: prompt-toolkit, ipython, PyPrind, py-stringmatching, py-stringsimjoin, py-entitymatching\n","  Found existing installation: prompt-toolkit 1.0.18\n","    Uninstalling prompt-toolkit-1.0.18:\n","      Successfully uninstalled prompt-toolkit-1.0.18\n","  Found existing installation: ipython 5.5.0\n","    Uninstalling ipython-5.5.0:\n","      Successfully uninstalled ipython-5.5.0\n","Successfully installed PyPrind-2.11.3 ipython-7.23.1 prompt-toolkit-3.0.18 py-entitymatching-0.4.0 py-stringmatching-0.4.2 py-stringsimjoin-0.3.2\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.colab-display-data+json":{"pip_warning":{"packages":["IPython","prompt_toolkit"]}}},"metadata":{"tags":[]}}]},{"cell_type":"code","metadata":{"id":"RCzAyqDiZ5-d","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1621794537404,"user_tz":-330,"elapsed":23740,"user":{"displayName":"Jay Rawal","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gicbrmn_Qxld9lob37iy1Q00RZQJCLx5AygrBt28Q=s64","userId":"02034246470089161035"}},"outputId":"99fe4f4d-0081-4cfe-dd26-2b7afe4da73e"},"source":["# https://hpi.de/naumann/projects/repeatability/datasets/restaurants-dataset.html\n","# http://www.iesl.cs.umass.edu/datasets.html - CORA dataset\n","# Importing the libraries\n","import sys\n","import pandas as pd\n","import os\n","from google.colab import drive\n","drive.mount('/content/gdrive')"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Mounted at /content/gdrive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"0rKhd_37C65k","executionInfo":{"status":"ok","timestamp":1621794541573,"user_tz":-330,"elapsed":502,"user":{"displayName":"Jay Rawal","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gicbrmn_Qxld9lob37iy1Q00RZQJCLx5AygrBt28Q=s64","userId":"02034246470089161035"}}},"source":["path_variable = \"/content/gdrive/My Drive/BTP/Code/Dataset/Restaurant/\"\n","method = \"/content/gdrive/My Drive/BTP/Code/Method1/weights_rest/\""],"execution_count":2,"outputs":[]},{"cell_type":"code","metadata":{"id":"iOTylBSTYLEQ","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1621794545820,"user_tz":-330,"elapsed":1868,"user":{"displayName":"Jay Rawal","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gicbrmn_Qxld9lob37iy1Q00RZQJCLx5AygrBt28Q=s64","userId":"02034246470089161035"}},"outputId":"9d56973c-547a-4f72-cd9d-d51c70f64b73"},"source":["import py_entitymatching as em\n","# Display the versions\n","print('python version: ' + sys.version )\n","print('pandas version: ' + pd.__version__ )\n","print('magellan version: ' + em.__version__ )"],"execution_count":3,"outputs":[{"output_type":"stream","text":["python version: 3.7.10 (default, May  3 2021, 02:48:31) \n","[GCC 7.5.0]\n","pandas version: 1.1.5\n","magellan version: 0.4.0\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"1vNlmQGBYLET","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1621794552376,"user_tz":-330,"elapsed":3972,"user":{"displayName":"Jay Rawal","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gicbrmn_Qxld9lob37iy1Q00RZQJCLx5AygrBt28Q=s64","userId":"02034246470089161035"}},"outputId":"0f9ca137-c5ac-4353-f180-046fd68cb822"},"source":["# Load csv files as dataframes and set the key attribute in the dataframe\n","path_A = path_variable+\"fodors.csv\"\n","path_B = path_variable+\"zagats.csv\"\n","A = em.read_csv_metadata(path_A, key='id')\n","B = em.read_csv_metadata(path_B, key='id')\n","\n","# Display number of tuples in the datasets\n","print('Number of tuples in A: ' + str(len(A)))\n","print('Number of tuples in B: ' + str(len(B)))\n","print('Number of tuples in A X B (i.e the cartesian product): ' + str(len(A)*len(B)))"],"execution_count":4,"outputs":[{"output_type":"stream","text":["Metadata file is not present in the given path; proceeding to read the csv file.\n","Metadata file is not present in the given path; proceeding to read the csv file.\n"],"name":"stderr"},{"output_type":"stream","text":["Number of tuples in A: 533\n","Number of tuples in B: 331\n","Number of tuples in A X B (i.e the cartesian product): 176423\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"K6lIYGbgugE_","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1621794554634,"user_tz":-330,"elapsed":15,"user":{"displayName":"Jay Rawal","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gicbrmn_Qxld9lob37iy1Q00RZQJCLx5AygrBt28Q=s64","userId":"02034246470089161035"}},"outputId":"7fafde25-b5c3-4305-a534-fccb0e03d298"},"source":["# verify values in S\n","\n","d1 = dict()\n","d2 = dict()\n","\n","t1 = A.to_numpy()\n","t2 = B.to_numpy()\n","\n","for x in t1:\n","  if(x[-1] in d1):\n","    d1[x[-1]]+=1\n","  else:\n","    d1[x[-1]]=1\n","\n","for x in t2:\n","  if(x[-1] in d2):\n","    d2[x[-1]]+=1\n","  else:\n","    d2[x[-1]]=1\n","\n","print(\"d1 : \",d1)\n","print(\"d2 : \",d2)"],"execution_count":5,"outputs":[{"output_type":"stream","text":["d1 :  {'American': 165, 'French/Italian/European': 164, 'Asian': 88, 'Diners/Cafes': 35, 'Fusion food(Mexican/mediterranean/caribbean)': 51, 'bbq/fast food': 30}\n","d2 :  {'American': 70, 'Asian': 69, 'Fusion food(Mexican/mediterranean/caribbean)': 31, 'bbq/fast food': 47, 'French/Italian/European': 70, 'Diners/Cafes': 44}\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"XPaC2dHKYLEk","executionInfo":{"status":"ok","timestamp":1621794564693,"user_tz":-330,"elapsed":5487,"user":{"displayName":"Jay Rawal","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gicbrmn_Qxld9lob37iy1Q00RZQJCLx5AygrBt28Q=s64","userId":"02034246470089161035"}}},"source":["import pickle\n","import numpy as np\n","import torch\n","\n","dbfile = open(path_variable+'files/feature_matrix_restaurant', 'rb')    \n","cand_file = open(path_variable+'files/C_restaurant', 'rb')  \n","S = pickle.load(dbfile)\n","cand = pickle.load(cand_file)\n","\n","S = torch.tensor(S.values,dtype=torch.double)\n","S = S[:,3:]\n","# S = S.to_numpy(dtype=np.longdouble)\n","device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n","\n","# Initial weights would be 1/(num_attributes*num_sim_scores) due to add-to-1 constraint\n","w_init  = (1 / S.shape[1] )\n","# W = np.full((S.shape[0], S.shape[1]), w_init,dtype=np.longdouble)\n","W = torch.DoubleTensor(S.shape[1],1).fill_(w_init)"],"execution_count":6,"outputs":[]},{"cell_type":"code","metadata":{"id":"fXsGWImAv3bh","executionInfo":{"status":"ok","timestamp":1621794566714,"user_tz":-330,"elapsed":9,"user":{"displayName":"Jay Rawal","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gicbrmn_Qxld9lob37iy1Q00RZQJCLx5AygrBt28Q=s64","userId":"02034246470089161035"}}},"source":["# ith index of genre_groups denotes genre of ith record pair\n","genre_groups = []\n","for i in cand['ltable_group']:\n","    genre_groups.append(i)"],"execution_count":7,"outputs":[]},{"cell_type":"code","metadata":{"id":"umeeQj0qrsJG","executionInfo":{"status":"ok","timestamp":1621794915253,"user_tz":-330,"elapsed":923,"user":{"displayName":"Jay Rawal","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gicbrmn_Qxld9lob37iy1Q00RZQJCLx5AygrBt28Q=s64","userId":"02034246470089161035"}}},"source":["######### Skew metric adopted from https://arxiv.org/pdf/1905.01989.pdf (refer this paper for the metric)\n","\n","# ith row of RLS matrix will return RLS value of the ith record pair \n","# return nx1 matrix, where n=number of record pairs \n","def get_RLS(W,S):\n","    rls = torch.matmul(S,torch.square(W))\n","    return rls\n","    # return torch.diag(rls)\n","\n","def fair_calc(weights,S,flag,k):\n","  \n","  rls_matrix = get_RLS(weights,S)\n","  cand['score'] = rls_matrix.numpy()\n","  candy = cand.sort_values(by=['score'], ascending=False)\n","\n","  # print(candy)\n","  # k=500\n","\n","  d3 = dict()\n","  d4 = dict()\n","\n","  temp = candy.to_numpy()\n","  cnt = 0\n","\n","  for _id,pair in enumerate(temp):\n","    # print(_id)\n","    # print(pair,pair[11],pair[20])\n","    if(_id>k):\n","      # print(_id)\n","      break\n","\n","    if(pair[9] in d3):\n","      d3[pair[9]]+=1\n","    else:\n","      d3[pair[9]]=1\n","      \n","    if(pair[-2] in d4):\n","      d4[pair[-2]]+=1\n","    else:\n","      d4[pair[-2]]=1\n","    \n","    if(pair[9]==(pair[-2])):\n","      cnt+=1\n","\n","  \n","  # print(\"d3 : \", d3)\n","  # print(\"d4 : \",d4)\n","\n","  # print(cnt)\n","  \n","  mini = -1\n","  maxi = 1\n","  d_skew = {}\n","  flagy = 0\n","  for d in d1.keys():\n","    if(d in d3.keys()):\n","      d_skew[d] = np.log( d3[d]*len(t1)/(d1[d]*k))\n","    \n","      if(flagy==0):\n","        flagy+=1\n","        mini = d_skew[d]\n","        maxi = d_skew[d]\n","      \n","      mini = min(mini,d_skew[d])\n","      maxi = max(maxi,d_skew[d])\n","    # else:\n","    #   print(d)\n","  \n","  if(flag):\n","    print(\"Group distribution in result : \",d3)\n","    print(\"Skew metrix : \", maxi-mini)\n","\n","  return maxi-mini\n","\n","\n","# def get_RLS_sum(W,S):\n","#     rls = torch.matmul(S,torch.transpose(W, 0, 1))\n","#     return torch.sum(torch.diag(rls))\n","\n","# this will return a 1D vector of size n , having value which is to be multiplied to 2*w*S \n","# returns an nx1 vector\n","# value at ith index would be multiplied to ith pair's derivative\n","\n","\n","# def derivative_loss_function(S,W,j,precomputed_value):\n","#     partial_deriv = 0\n","#     for i in range(S.shape[0]):\n","#         num = 2 * S[j,:].dot(W[j,:]) * ( torch.exp(phi * S[i,:].dot(W[i,:])) - torch.exp(phi * (tau - S[i,:].dot(W[i,:]) )) )\n","#         denom = torch.exp(phi * S[i,:].dot(W[i,:])) + torch.exp(phi * (tau - S[i,:].dot(W[i,:])))\n","#         partial_deriv += num/denom\n","#     return partial_deriv\n","\n","\n","def get_precomputed_values(W,S,phi,tau):\n","    numerator = torch.exp(phi*get_RLS(W,S)) - torch.exp(phi* (tau-get_RLS(W,S)))\n","    # print(numerator)\n","    denominator = torch.exp(phi*get_RLS(W,S)) + torch.exp(phi* (tau-get_RLS(W,S)))\n","    return torch.divide(numerator,denominator)\n","\n","\n","def derivative_loss_function(W,S,j,precomputed_values):\n","    # print(S[:,j].reshape(-1,1).shape)\n","    # print(torch.transpose(S[:,j],0,1).shape)\n","    # print(precomputed_values.shape)\n","    m = torch.matmul(torch.transpose(S[:,j].reshape(-1,1),0,1),precomputed_values)\n","    der = 2 * W[j,0] * m\n","    return der\n","\n","def algorithm_gradient_descent(W,S,learning_rate,iterations,phi,tau,flag_tweak,k):\n","\n","    for i in range(iterations):\n","        W_new = torch.zeros(W.shape) \n","        sum_W_new = 0\n","        precomputed_values_em = get_precomputed_values(W,S,phi,tau)\n","        for j in range(W.shape[0]):\n","            loss_value = derivative_loss_function(W,S,j,precomputed_values_em)\n","            W_new[j,0] = W[j,0] - learning_rate * loss_value\n","            if( W_new[j,0] != float(\"nan\")):\n","              sum_W_new += W_new[j,0]\n","        # print(sum_W_new)\n","\n","        for j in range(W.shape[0]):\n","            W_new[j,0] = W_new[j,0] / float(sum_W_new)\n","        W = W_new.double()\n","        # print(W)\n","        if((i+1)%10==0):\n","          print(\"Iteration \" + str(i+1) + \" completed \")        \n","        \n","        if(flag_tweak):\n","          f_val = fair_calc(W,S,False,k)\n","          epsi = 0.1\n","\n","          for j in range(W.shape[0]):\n","            W[j,0] += epsi\n","            f1 = fair_calc(W,S,False,k)\n","            \n","            W[j,0] -= 2*epsi\n","            f2 = fair_calc(W,S,False,k)\n","            # print(f1,f2,f_val)\n","            if(f_val<=f1 and f_val<=f2):\n","              # print(\"val\")\n","              W[j,0] += epsi\n","\n","            elif(f1<=f2 and f1<=f_val):\n","              # print(\"f1\")\n","              W[j,0] += 2*epsi\n","        # print(W)\n","\n","    return W"],"execution_count":20,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"OA5peIsibE4_","executionInfo":{"status":"ok","timestamp":1621765323466,"user_tz":-330,"elapsed":11,"user":{"displayName":"Jay Rawal","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gicbrmn_Qxld9lob37iy1Q00RZQJCLx5AygrBt28Q=s64","userId":"02034246470089161035"}},"outputId":"34997b9d-eded-4264-d7a3-d77d2226ebb1"},"source":["#No learning\n","print(W)\n","fair_calc(W,S,True,500)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["tensor([[0.0500],\n","        [0.0500],\n","        [0.0500],\n","        [0.0500],\n","        [0.0500],\n","        [0.0500],\n","        [0.0500],\n","        [0.0500],\n","        [0.0500],\n","        [0.0500],\n","        [0.0500],\n","        [0.0500],\n","        [0.0500],\n","        [0.0500],\n","        [0.0500],\n","        [0.0500],\n","        [0.0500],\n","        [0.0500],\n","        [0.0500],\n","        [0.0500]], dtype=torch.float64)\n","Group distribution in result :  {'American': 98, 'French/Italian/European': 163, 'bbq/fast food': 45, 'Fusion food(Mexican/mediterranean/caribbean)': 58, 'Asian': 78, 'Diners/Cafes': 59}\n","Skew metrix :  1.0431673776463146\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["1.0431673776463146"]},"metadata":{"tags":[]},"execution_count":17}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Z--XMvBcWYRA","executionInfo":{"status":"ok","timestamp":1621794923036,"user_tz":-330,"elapsed":616,"user":{"displayName":"Jay Rawal","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gicbrmn_Qxld9lob37iy1Q00RZQJCLx5AygrBt28Q=s64","userId":"02034246470089161035"}},"outputId":"ee6620be-e0ac-4626-ba40-f2dd402c389f"},"source":["#No tweak of weights\n","weights1 = algorithm_gradient_descent(W,S,1e-5,100,-100,1,False,500)"],"execution_count":21,"outputs":[{"output_type":"stream","text":["Iteration 10 completed \n","Iteration 20 completed \n","Iteration 30 completed \n","Iteration 40 completed \n","Iteration 50 completed \n","Iteration 60 completed \n","Iteration 70 completed \n","Iteration 80 completed \n","Iteration 90 completed \n","Iteration 100 completed \n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"NStwmy5_dwe0","executionInfo":{"status":"ok","timestamp":1621794930882,"user_tz":-330,"elapsed":976,"user":{"displayName":"Jay Rawal","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gicbrmn_Qxld9lob37iy1Q00RZQJCLx5AygrBt28Q=s64","userId":"02034246470089161035"}},"outputId":"d6f99aa0-6faf-4790-f0f6-09be611d25b5"},"source":["print(weights1)\n","fair_calc(weights1,S,True,500)"],"execution_count":22,"outputs":[{"output_type":"stream","text":["tensor([[1.8963e-01],\n","        [2.6903e-01],\n","        [1.6531e-03],\n","        [4.2786e-02],\n","        [1.0905e-02],\n","        [3.5550e-03],\n","        [9.6568e-05],\n","        [8.1715e-04],\n","        [2.5778e-03],\n","        [6.1307e-03],\n","        [7.0380e-05],\n","        [7.7878e-04],\n","        [1.6857e-01],\n","        [2.5376e-01],\n","        [1.6839e-03],\n","        [3.8954e-02],\n","        [6.5933e-03],\n","        [3.2759e-04],\n","        [1.7551e-03],\n","        [3.2718e-04]], dtype=torch.float64)\n","Group distribution in result :  {'American': 196, 'French/Italian/European': 176, 'Fusion food(Mexican/mediterranean/caribbean)': 30, 'bbq/fast food': 18, 'Asian': 69, 'Diners/Cafes': 12}\n","Skew metrix :  1.24261059703135\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["1.24261059703135"]},"metadata":{"tags":[]},"execution_count":22}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"5GK2PZlmW2KA","executionInfo":{"status":"ok","timestamp":1621794953997,"user_tz":-330,"elapsed":18670,"user":{"displayName":"Jay Rawal","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gicbrmn_Qxld9lob37iy1Q00RZQJCLx5AygrBt28Q=s64","userId":"02034246470089161035"}},"outputId":"983b0fca-9d8c-49d8-9f9b-d545956f622c"},"source":["#Tweak weights\n","weights2 = algorithm_gradient_descent(W,S,1e-5,100,-100,1,True,500)"],"execution_count":23,"outputs":[{"output_type":"stream","text":["Iteration 10 completed \n","Iteration 20 completed \n","Iteration 30 completed \n","Iteration 40 completed \n","Iteration 50 completed \n","Iteration 60 completed \n","Iteration 70 completed \n","Iteration 80 completed \n","Iteration 90 completed \n","Iteration 100 completed \n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"KtePd7T-dyQE","executionInfo":{"status":"ok","timestamp":1621794958785,"user_tz":-330,"elapsed":1238,"user":{"displayName":"Jay Rawal","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gicbrmn_Qxld9lob37iy1Q00RZQJCLx5AygrBt28Q=s64","userId":"02034246470089161035"}},"outputId":"5a08534e-398d-4c14-9c3b-f9f62e00bd34"},"source":["print(weights2)\n","fair_calc(weights2,S,True,500)"],"execution_count":24,"outputs":[{"output_type":"stream","text":["tensor([[nan],\n","        [nan],\n","        [nan],\n","        [nan],\n","        [nan],\n","        [nan],\n","        [nan],\n","        [nan],\n","        [nan],\n","        [nan],\n","        [nan],\n","        [nan],\n","        [nan],\n","        [nan],\n","        [nan],\n","        [nan],\n","        [nan],\n","        [nan],\n","        [nan],\n","        [nan]], dtype=torch.float64)\n","Group distribution in result :  {'French/Italian/European': 177, 'bbq/fast food': 25, 'American': 169, 'Asian': 58, 'Fusion food(Mexican/mediterranean/caribbean)': 46, 'Diners/Cafes': 26}\n","Skew metrix :  0.49317710868141795\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["0.49317710868141795"]},"metadata":{"tags":[]},"execution_count":24}]},{"cell_type":"code","metadata":{"id":"n0vVl1MZ-H5c"},"source":["def comp_overlap(w1,w2,k):\n","  rls_matrix = get_RLS(w1,S)\n","  cand['score'] = rls_matrix.numpy()\n","  candy1 = cand.sort_values(by=['score'], ascending=False)\n","\n","  # print(candy)\n","\n","  dw1 = dict()\n","  temp1 = candy1.to_numpy()\n","  \n","  rls_matrix = get_RLS(w2,S)\n","  cand['score'] = rls_matrix.numpy()\n","  candy2 = cand.sort_values(by=['score'], ascending=False)\n","\n","  # print(candy)\n","  dw2 = dict()\n","  temp2 = candy2.to_numpy()\n","  overlp = 0\n","  \n","  # print(candy1)\n","  # print(candy2)\n","\n","  # print(temp1[0][1],temp1[0][2])\n","  # print(temp1)\n","  # print(temp2)\n","  # return \n","  dname = {}\n","\n","  \n","  for _i,i in enumerate(temp1):\n","    if(_i>k-1):\n","      break\n","    dname[str(i[1])+\"#\"+str(i[2])] = 1\n","  \n","  # print(len(dname))\n","\n","  for _j,j in enumerate(temp2):\n","      if(_j>k-1):\n","        break\n","      if(str(j[1])+\"#\"+str(j[2]) in  dname.keys()):\n","        overlp+=1\n","  \n","  return overlp\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"QtaSH2eJOBkb","executionInfo":{"status":"ok","timestamp":1621765469588,"user_tz":-330,"elapsed":71193,"user":{"displayName":"Jay Rawal","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gicbrmn_Qxld9lob37iy1Q00RZQJCLx5AygrBt28Q=s64","userId":"02034246470089161035"}},"outputId":"8a4b9a39-b22f-412a-ef84-fc43ff1d52ac"},"source":["i=0\n","w_list = []\n","\n","for k in [250,500,750,1000]:\n","  w_list.append(algorithm_gradient_descent(W,S,1e-5,100,-100,1,True,k))\n","  i+=1"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Iteration 10 completed \n","Iteration 20 completed \n","Iteration 30 completed \n","Iteration 40 completed \n","Iteration 50 completed \n","Iteration 60 completed \n","Iteration 70 completed \n","Iteration 80 completed \n","Iteration 90 completed \n","Iteration 100 completed \n","Iteration 10 completed \n","Iteration 20 completed \n","Iteration 30 completed \n","Iteration 40 completed \n","Iteration 50 completed \n","Iteration 60 completed \n","Iteration 70 completed \n","Iteration 80 completed \n","Iteration 90 completed \n","Iteration 100 completed \n","Iteration 10 completed \n","Iteration 20 completed \n","Iteration 30 completed \n","Iteration 40 completed \n","Iteration 50 completed \n","Iteration 60 completed \n","Iteration 70 completed \n","Iteration 80 completed \n","Iteration 90 completed \n","Iteration 100 completed \n","Iteration 10 completed \n","Iteration 20 completed \n","Iteration 30 completed \n","Iteration 40 completed \n","Iteration 50 completed \n","Iteration 60 completed \n","Iteration 70 completed \n","Iteration 80 completed \n","Iteration 90 completed \n","Iteration 100 completed \n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"GkQOkbSyOK-c"},"source":["weight_file = open(method+'weights_list', 'wb') \n","pickle.dump(w_list, weight_file) \n","weight_file.close()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"kYAEmxgl91sS"},"source":["weight_file = open(method+'weights1', 'wb') \n","pickle.dump(weights1, weight_file) \n","weight_file.close()\n","\n","weight_file = open(method+'weights2', 'wb') \n","pickle.dump(weights2, weight_file) \n","weight_file.close()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"u6Z8VvReq1b9"},"source":["weight_file = open(method+'weights1', 'rb') \n","weights1 = pickle.load(weight_file)\n","\n","weight_file = open(method+'weights2', 'rb') \n","weights2 = pickle.load(weight_file)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"g6FJzxmaYLEn","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1621765526383,"user_tz":-330,"elapsed":532,"user":{"displayName":"Jay Rawal","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gicbrmn_Qxld9lob37iy1Q00RZQJCLx5AygrBt28Q=s64","userId":"02034246470089161035"}},"outputId":"ad783a35-79ee-4e92-9d88-00a906912669"},"source":["l = get_RLS(weights2,S)\n","se = set()\n","print(l.shape)\n","for i in range(l.shape[0]):\n","    se.add(float(l[i,0]))\n","print(se)\n","print(len(se))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["torch.Size([4951, 1])\n","{nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan}\n","4951\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"-BxVPiRUWHcW","executionInfo":{"status":"ok","timestamp":1621765580262,"user_tz":-330,"elapsed":414,"user":{"displayName":"Jay Rawal","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gicbrmn_Qxld9lob37iy1Q00RZQJCLx5AygrBt28Q=s64","userId":"02034246470089161035"}},"outputId":"0c5eceae-ce2a-4c73-b299-b9d97eccdd5f"},"source":["path_G = path_variable+\"matches_fodors_zagats.csv\"\n","G = em.read_csv_metadata(path_G, \n","                        #  key='_id',\n","                         ltable=A, rtable=B, \n","                         fk_ltable='fodors_id', fk_rtable='zagats_id')\n","\n","# print(G)\n","print(len(G))\n","\n","gdic = {}\n","cnt_g = 0\n","\n","G1 = G.to_numpy()\n","for i,x in enumerate(G1):\n","  s = str(x[0])+\"#\"+str(x[1])  \n","  s1 = str(x[1])+\"#\"+str(x[0])\n","  # print(s)\n","  gdic[s] = 1\n","  gdic[s1] = 1\n","\n","print(\"Positive in ground truth\",len(gdic)/2)\n","print(gdic.keys())\n","\n","def check_gt(w1,S,k):\n","  rls_matrix = get_RLS(w1,S)\n","  cand['score'] = rls_matrix.numpy()\n","  candy1 = cand.sort_values(by=['score'], ascending=False)\n","  temp1 = candy1.to_numpy()\n","  \n","  overlp = 0\n","  neg = 0\n","\n","  for _j,j in enumerate(temp1):\n","      if(_j>k-1):\n","        break\n","      s = str(j[1])+\"#\"+str(j[2])\n","\n","      if(s in  gdic.keys()):\n","        # print(s)\n","        if(gdic[s]==1):\n","          overlp+=1\n","        else:\n","          neg+=1\n","\n","  return overlp,neg"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Metadata file is not present in the given path; proceeding to read the csv file.\n"],"name":"stderr"},{"output_type":"stream","text":["112\n","Positive in ground truth 112.0\n","dict_keys(['534#219', '219#534', '535#220', '220#535', '536#221', '221#536', '537#222', '222#537', '538#223', '223#538', '539#224', '224#539', '540#225', '225#540', '541#226', '226#541', '542#227', '227#542', '543#228', '228#543', '544#229', '229#544', '545#230', '230#545', '546#231', '231#546', '547#232', '232#547', '548#233', '233#548', '549#234', '234#549', '550#235', '235#550', '551#236', '236#551', '552#237', '237#552', '553#238', '238#553', '554#239', '239#554', '555#240', '240#555', '556#241', '241#556', '557#242', '242#557', '558#243', '243#558', '559#244', '244#559', '560#245', '245#560', '561#246', '246#561', '562#247', '247#562', '563#248', '248#563', '564#249', '249#564', '565#250', '250#565', '566#251', '251#566', '567#252', '252#567', '568#253', '253#568', '569#254', '254#569', '570#255', '255#570', '571#256', '256#571', '572#257', '257#572', '573#258', '258#573', '574#259', '259#574', '575#260', '260#575', '576#261', '261#576', '577#262', '262#577', '578#263', '263#578', '579#264', '264#579', '580#265', '265#580', '581#266', '266#581', '582#267', '267#582', '583#268', '268#583', '584#269', '269#584', '585#270', '270#585', '586#271', '271#586', '587#272', '272#587', '588#273', '273#588', '589#274', '274#589', '590#275', '275#590', '591#276', '276#591', '592#277', '277#592', '593#278', '278#593', '594#279', '279#594', '595#280', '280#595', '596#281', '281#596', '597#282', '282#597', '598#283', '283#598', '599#284', '284#599', '600#285', '285#600', '601#286', '286#601', '602#287', '287#602', '603#288', '288#603', '604#289', '289#604', '605#290', '290#605', '606#291', '291#606', '607#292', '292#607', '608#293', '293#608', '609#294', '294#609', '610#295', '295#610', '611#296', '296#611', '612#297', '297#612', '613#298', '298#613', '614#299', '299#614', '615#300', '300#615', '616#301', '301#616', '617#302', '302#617', '618#303', '303#618', '619#304', '304#619', '620#305', '305#620', '621#306', '306#621', '622#307', '307#622', '623#308', '308#623', '624#309', '309#624', '625#310', '310#625', '626#311', '311#626', '627#312', '312#627', '628#313', '313#628', '629#314', '314#629', '630#315', '315#630', '631#316', '316#631', '632#317', '317#632', '633#318', '318#633', '634#319', '319#634', '635#320', '320#635', '636#321', '321#636', '637#322', '322#637', '638#323', '323#638', '639#324', '324#639', '640#325', '325#640', '641#326', '326#641', '642#327', '327#642', '643#328', '328#643', '644#329', '329#644', '645#330', '330#645'])\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"AYamw5hMC7ND","executionInfo":{"status":"ok","timestamp":1621765587362,"user_tz":-330,"elapsed":377,"user":{"displayName":"Jay Rawal","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gicbrmn_Qxld9lob37iy1Q00RZQJCLx5AygrBt28Q=s64","userId":"02034246470089161035"}},"outputId":"c2f86381-be79-4139-9d1e-351a7e2062fa"},"source":["weight_file = open(method+'weights_list', 'rb') \n","w_list = pickle.load(weight_file)\n","\n","i=0\n","for k in [250,500,750,1000]:\n","  print(\"Top-\",k)\n","  weight_this = w_list[i]\n","  i+=1\n","  # print(\"Weights =\",weight_this)\n","  print(\"Fairness skew for w1 \" + \" is \"+ str(fair_calc(weights1,S,False,k)))\n","  print(\"Fairness skew for w\" + str(k)+ \" is \"+ str(fair_calc(weight_this,S,False,k)))\n","  print(\"Overlap with base result = \"+str(comp_overlap(weights1,weight_this,k))+\" /\"+ str(k))\n","  print(\"Overlap with ground truth weights1\", check_gt(weights1,S,k))\n","  print(\"Overlap with ground truth weights_this\", check_gt(weight_this,S,k),\"\\n\")\n"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Top- 250\n","Fairness skew for w1  is 0.9507510704887621\n","Fairness skew for w250 is 0.7102760628229126\n","Overlap with base result = 8 /250\n","Overlap with ground truth weights1 (95, 0)\n","Overlap with ground truth weights_this (0, 0) \n","\n","Top- 500\n","Fairness skew for w1  is 1.24261059703135\n","Fairness skew for w500 is 0.49317710868141795\n","Overlap with base result = 44 /500\n","Overlap with ground truth weights1 (102, 0)\n","Overlap with ground truth weights_this (0, 0) \n","\n","Top- 750\n","Fairness skew for w1  is 1.3611492050697311\n","Fairness skew for w750 is 0.20657853443951454\n","Overlap with base result = 453 /750\n","Overlap with ground truth weights1 (103, 0)\n","Overlap with ground truth weights_this (104, 0) \n","\n","Top- 1000\n","Fairness skew for w1  is 1.063200250444854\n","Fairness skew for w1000 is 0.22129770840124618\n","Overlap with base result = 388 /1000\n","Overlap with ground truth weights1 (103, 0)\n","Overlap with ground truth weights_this (105, 0) \n","\n"],"name":"stdout"}]}]}